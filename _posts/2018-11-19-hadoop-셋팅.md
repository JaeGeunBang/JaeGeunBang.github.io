---
layout: post
title: "hadoop 기본 셋팅"
categories:
  - Posts
tags:
  - hadoop
last_modified_at: 2018-11-19T12:57:42+09:00
---


### 1. Hadoop은 크게 3가지 모드로 셋팅 할 수 있음
	1. Local Standard Mode
    2. Pseudo-Distributed Mode
    3. Fully-Distributed Mode

1. Local Standard Mode
- 하나의 노드 내 하나의 Java Process에서 하둡을 하고 싶을 때 설정하며, 디버깅 용도로 주로 사용함

```
$ mkdir input
$ cp etc/hadoop/*.xml input
$ bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-3.1.1.jar grep input output 'dfs[a-z.]+'
$ cat output/*
```

2. Pseudo-Distributed Mode
	- 하나의 노드 내 여러 Java Process에서 하둡을 사용 하고 싶을 때 설정함.
3. Fully-Distributed Mode
	- 여러 노드에서 하둡을 사용할 때 설정함.
    - Psuedo-Distributed Mode를 여러 노드에서 하면 됨

### 2. 셋팅
- 3대 노드 준비 (VM)

```
Master: Hadoop-1 (192.168.56.191)
Slave: Hadoop-2 (192.168.56.192)
Slave: Hadoop-3 (192.168.56.193)
```

- master 노드가 slave 노드에 password 없이 접속이 가능해야함 (Master 노드에서만 작업)

```
$ ssh-keygen -t rsa 

$ ssh 192.168.56.192 mkdir -p .ssh
$ ssh 192.168.56.193 mkdir -p .ssh

$ cat ~/.ssh/id_rsa.pub | ssh 192.168.56.192 'cat >> ~/.ssh/authorized_keys'
$ cat ~/.ssh/id_rsa.pub | ssh 192.168.56.193 'cat >> ~/.ssh/authorized_keys'
```
> password 없이 접속이 안된다면, 아래 퍼미션을 확인해 볼 것.
```
chmod 700 ~/.ssh
chmod 600 ~/.ssh/id_rsa (private key)
chmod 644 ~/.ssh/id_rsa.pub (public key)
chmod 644 ~/.ssh/authorized_keys (public key in remote server)
chmod 644 ~/.ssh/known_hosts
```
> ssh 포트가 22가 아닐 경우
```
mkdir ~/.ssh/config
chmod 600 ~/.ssh/config
```
>> .ssh/config
```
Host 192.168.56.192
    port 5858 (ssh port가 5858일 경우)
Host 192.168.56.193
    port 5858
```

- 각 노드에 자바와 하둡을 설치함

```
하둡 버전: 2.9.1
자바 설치 후 아래 파일에 자바 경로를 등록함
/etc/hadoop/hadoop-env.sh
export JAVA_HOME=/usr/lib/jvm/java-1.8.0-openjdk-amd64

```

- 저장 디렉토리 생성

```
$ sudo mkdir -p /data/hadoop/tmp
$ sudo mkdir -p /data/hadoop/dfs/name
$ sudo mkdir -p /data/hadoop/dfs/data

$ sudo chown -R user:user /data/hadoop
```

- Config 설정

	- etc/hadoop/core-site.xml
    
```
<configuration>
  <property>
    <name>fs.defaultFS</name>
    <value>hdfs://192.168.56.191:9000</value>
  </property>
  <property>
   <name>hadoop.tmp.dir</name>
   <value>/data/hadoop/tmp</value>
  </property>
</configuration>
```
- etc/hadoop/hdfs-site.xml
    
```
<configuration>
    <property>
        <name>dfs.replication</name>
        <value>1</value>
    </property>
    <property>
        <name>dfs.namenode.name.dir</name>
        <value>file:/data/hadoop/dfs/name</value>
        <final>true</final>
    </property>
    <property>
        <name>dfs.datanode.data.dir</name>
        <value>file:/data/hadoop/dfs/data</value>
        <final>true</final>
    </property>

    <property>
        <name>dfs.permissions</name>
        <value>false</value>
    </property>
</configuration>
```

- etc/hadoop/yarn-site.xml

```
<configuration>
<!-- Site specific YARN configuration properties -->
  <property>
    <name>yarn.nodemanager.aux-services</name>
    <value>mapreduce_shuffle</value>
  </property>
  <property>
    <name>yarn.nodemanager.aux-services.mapreduce_shuffle.class</name>
    <value>org.apache.hadoop.mapred.ShuffleHandler</value>
  </property>
  <property>
    <name>yarn.resourcemanager.resource-tracker.address</name>
    <value>192.168.56.191:8025</value>
  </property>
  <property>
    <name>yarn.resourcemanager.scheduler.address</name>
    <value>192.168.56.191:8030</value>
  </property>
  <property>
    <name>yarn.resourcemanager.address</name>
    <value>192.168.56.191:8035</value>
  </property>
</configuration>
```

- etc/hadoop/slaves

```
192.168.56.192
192.168.56.193
```

- 셋팅 완료 후 모든 노드에 복사함

```
rsync -avz ~/hadoop-2.9.1 192.168.56.192:/home/user
rsync -avz ~/hadoop-2.9.1 192.168.56.193:/home/user
```

### 3. 실행

- namenode format

```
./bin/hadoop namenode -format
```

- dfs, yarn 실행

```
./sbin/start-dfs-.sh
./sbin/start-yarn.sh
수행 후 jps를 통해 각 서비스들이 떠있는지 확인
master: NameNode, ResourceManager, SecondaryNameNode
slave: DataNode, NodeManager
```

# 참고
https://hadoop.apache.org/docs/r3.1.1/hadoop-project-dist/hadoop-common/SingleCluster.html
